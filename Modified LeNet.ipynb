{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d472d1",
   "metadata": {},
   "source": [
    "The dataset for Sign Language MNIST comes from https://www.kaggle.com/datasets/datamunge/sign-language-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a416411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.neural_network = nn.Sequential(\n",
    "            \n",
    "            # Layer 1\n",
    "            nn.Conv2d(1,6,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(16, 120, 5),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # FC\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 25),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e850f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(np.reshape(self.data.iloc[idx, 1:], (28, 28)).astype(np.uint8))\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1941f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Pad(2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "training_set = CustomImageDataset(\"data/signs/sign_mnist_train.csv\", transform=transform)\n",
    "test_set = CustomImageDataset(\"data/signs/sign_mnist_test.csv\", transform=transform)\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b610c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader): \n",
    "        (X, y) = data # len(X) = 10\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1000 == 0 and batch > 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c6170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.154349  [ 4000/27455]\n",
      "loss: 3.070931  [ 8000/27455]\n",
      "loss: 1.754682  [12000/27455]\n",
      "loss: 1.248746  [16000/27455]\n",
      "loss: 0.459929  [20000/27455]\n",
      "loss: 0.371831  [24000/27455]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.511846 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.316371  [ 4000/27455]\n",
      "loss: 0.008893  [ 8000/27455]\n",
      "loss: 0.000030  [12000/27455]\n",
      "loss: 0.034138  [16000/27455]\n",
      "loss: 0.000096  [20000/27455]\n",
      "loss: 0.011527  [24000/27455]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.377763 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.001889  [ 4000/27455]\n",
      "loss: 0.000772  [ 8000/27455]\n",
      "loss: 0.001391  [12000/27455]\n",
      "loss: 0.001600  [16000/27455]\n",
      "loss: 0.000037  [20000/27455]\n",
      "loss: 0.000912  [24000/27455]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.374232 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedLeNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(training_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d90b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
